#!/usr/bin/env python3
"""
–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –≤—Å–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ Nexy
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥—É–ª–µ–π –≤ –µ–¥–∏–Ω—É—é —Ç–æ—á–∫—É —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
"""

import os
import yaml
from pathlib import Path
from typing import Dict, Any, Optional, Union
from dataclasses import dataclass, field
import logging

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ config.env
config_path = Path(__file__).parent.parent / "config.env"
if config_path.exists():
    with open(config_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º rsplit –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–∞–∑–±–æ—Ä–∞ —Å—Ç—Ä–æ–∫ —Å = –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö
                key, value = line.rsplit('=', 1)
                os.environ[key.strip()] = value.strip()

logger = logging.getLogger(__name__)

@dataclass
class DatabaseConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    host: str = "localhost"
    port: int = 5432
    name: str = "voice_assistant_db"
    user: str = "postgres"
    password: str = ""
    
    @classmethod
    def from_env(cls) -> 'DatabaseConfig':
        return cls(
            host=os.getenv('DB_HOST', 'localhost'),
            port=int(os.getenv('DB_PORT', '5432')),
            name=os.getenv('DB_NAME', 'voice_assistant_db'),
            user=os.getenv('DB_USER', 'postgres'),
            password=os.getenv('DB_PASSWORD', '')
        )

@dataclass
class GrpcConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è gRPC —Å–µ—Ä–≤–µ—Ä–∞"""
    host: str = "0.0.0.0"
    port: int = 50051
    max_workers: int = 10
    
    @classmethod
    def from_env(cls) -> 'GrpcConfig':
        return cls(
            host=os.getenv('GRPC_HOST', '0.0.0.0'),
            port=int(os.getenv('GRPC_PORT', '50051')),
            max_workers=int(os.getenv('MAX_WORKERS', '10'))
        )

@dataclass
class AudioConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ (—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å –∫–ª–∏–µ–Ω—Ç–æ–º)"""
    sample_rate: int = 48000
    chunk_size: int = 1024
    format: str = "int16"
    channels: int = 1
    bits_per_sample: int = 16
    
    # Azure TTS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    azure_speech_key: str = ""
    azure_speech_region: str = ""
    azure_voice_name: str = "en-US-AriaNeural"
    azure_voice_style: str = "friendly"
    azure_speech_rate: float = 1.0
    azure_speech_pitch: float = 1.0
    azure_speech_volume: float = 1.0
    azure_audio_format: str = "riff-48khz-16bit-mono-pcm"
    
    # Streaming –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    streaming_chunk_size: int = 4096
    streaming_enabled: bool = True
    
    @classmethod
    def from_env(cls) -> 'AudioConfig':
        return cls(
            sample_rate=int(os.getenv('SAMPLE_RATE', '48000')),
            chunk_size=int(os.getenv('CHUNK_SIZE', '1024')),
            format=os.getenv('AUDIO_FORMAT', 'int16'),
            channels=int(os.getenv('AUDIO_CHANNELS', '1')),
            bits_per_sample=int(os.getenv('AUDIO_BITS_PER_SAMPLE', '16')),
            azure_speech_key=os.getenv('AZURE_SPEECH_KEY', ''),
            azure_speech_region=os.getenv('AZURE_SPEECH_REGION', ''),
            azure_voice_name=os.getenv('AZURE_VOICE_NAME', 'en-US-AriaNeural'),
            azure_voice_style=os.getenv('AZURE_VOICE_STYLE', 'friendly'),
            azure_speech_rate=float(os.getenv('AZURE_SPEECH_RATE', '1.0')),
            azure_speech_pitch=float(os.getenv('AZURE_SPEECH_PITCH', '1.0')),
            azure_speech_volume=float(os.getenv('AZURE_SPEECH_VOLUME', '1.0')),
            azure_audio_format=os.getenv('AZURE_AUDIO_FORMAT', 'riff-48khz-16bit-mono-pcm'),
            streaming_chunk_size=int(os.getenv('STREAMING_CHUNK_SIZE', '4096')),
            streaming_enabled=os.getenv('STREAMING_ENABLED', 'true').lower() == 'true'
        )

@dataclass
class TextProcessingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"""
    gemini_api_key: str = ""
    
    # Live API –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    gemini_live_model: str = "gemini-live-2.5-flash-preview"
    gemini_live_temperature: float = 0.7
    gemini_live_max_tokens: int = 2048
    gemini_live_tools: list = field(default_factory=lambda: ['google_search'])
    gemini_system_prompt: str = (
        "You are Nexy Assistant ‚Äî a friendly, empathetic, conversational AI for blind and low-vision users. "
        "Be warm and social, yet always concise and on-point. First answer the user‚Äôs question directly, then add only the minimal helpful context or next steps. Never ramble.\n\n"
        "Language and tone:\n"
        "- CRITICAL: You MUST respond ONLY in English. Never use Russian, Spanish, French, or any other language.\n"
        "- If the user writes in another language, understand it but respond in English.\n"
        "- Be friendly and encouraging, but keep answers tight and actionable.\n"
        "- Prefer bullet points and short paragraphs over long prose.\n\n"
        "Core intents (auto-detect per message):\n"
        "1) SmallTalk ‚Äî greetings, feelings, casual or personal questions. Keep 1‚Äì2 sentences; optional brief follow-up only if valuable.\n"
        "   Trigger examples: ‚Äòhi‚Äô, ‚Äòhow are you‚Äô, ‚Äòtell me about yourself‚Äô, ‚ÄòI feel sad today‚Äô.\n"
        "   Output: short supportive reply; optionally one kind follow-up question.\n"
        "2) Describe (text/image/screen) ‚Äî ONLY when the USER explicitly asks to describe/read/identify. The app continuously provides screenshots ‚Äî do NOT auto-describe them.\n"
        "   Trigger examples: ‚Äòdescribe the screen‚Äô, ‚Äòwhat‚Äôs in the top-left‚Äô, ‚Äòread this window text‚Äô, ‚Äòwhat‚Äôs in this photo‚Äô.\n"
        "   Output structure: brief overview ‚Üí key elements with spatial hints ‚Üí exact visible text ‚Üí notable states/controls ‚Üí 2‚Äì3 suggested next actions. No speculation; if a crucial detail is unclear, ask ONE clarifying question and still give best-effort.\n"
        "3) WebSearch ‚Äî when the user requests online/current info (news, prices, availability, comparisons) or facts you are uncertain about.\n"
        "   Trigger examples: ‚Äòlatest news on ‚Ä¶‚Äô, ‚Äòcurrent price of ‚Ä¶‚Äô, ‚Äòcompare models ‚Ä¶‚Äô, ‚Äòevents this weekend‚Äô, ‚Äòwhat‚Äôs the weather in ‚Ä¶‚Äô.\n"
        "   Output: concise synthesis + 1‚Äì3 labeled source links; include dates/regions when relevant; if search fails, say so and propose a fallback.\n\n"
        "Safety & link hygiene:\n"
        "- Briefly flag risky links/sources (non-HTTPS except localhost, suspicious domains/typosquats, unknown URL shorteners, auto-download pages, credential requests).\n"
        "- When flagging risk, add a one-line warning and propose a safer alternative if possible.\n"
        "- Prefer reputable sources. Do not ask users to disable security protections or run unverified scripts.\n\n"
        "General rules:\n"
        "- If uncertain, ask ONE clarifying question only if necessary to proceed.\n"
        "- Accessibility first: clarity, structure, direct guidance.\n"
        "- If a task spans multiple intents, prioritize Describe > WebSearch > SmallTalk by user utility.\n\n"
        "Output style:\n"
        "- Lead with the direct answer.\n"
        "- Then optional bullets: context, steps, or options.\n"
        "- Keep responses brief; no filler."
    )
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    image_format: str = "jpeg"
    image_mime_type: str = "image/jpeg"
    image_max_size: int = 10 * 1024 * 1024  # 10MB
    streaming_chunk_size: int = 8192
    
    
    # Fallback –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    fallback_timeout: int = 30
    circuit_breaker_threshold: int = 3
    circuit_breaker_timeout: int = 300
    
    # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    max_concurrent_requests: int = 10
    request_timeout: int = 60
    
    @classmethod
    def from_env(cls) -> 'TextProcessingConfig':
        return cls(
            gemini_api_key=os.getenv('GEMINI_API_KEY', ''),
            gemini_live_model=os.getenv('GEMINI_LIVE_MODEL', 'gemini-live-2.5-flash-preview'),
            gemini_live_temperature=float(os.getenv('GEMINI_LIVE_TEMPERATURE', '0.7')),
            gemini_live_max_tokens=int(os.getenv('GEMINI_LIVE_MAX_TOKENS', '2048')),
            gemini_live_tools=os.getenv('GEMINI_LIVE_TOOLS', 'google_search').split(',') if os.getenv('GEMINI_LIVE_TOOLS') else ['google_search'],
            gemini_system_prompt=os.getenv('GEMINI_SYSTEM_PROMPT', cls.gemini_system_prompt),
            image_format=os.getenv('IMAGE_FORMAT', 'jpeg'),
            image_mime_type=os.getenv('IMAGE_MIME_TYPE', 'image/jpeg'),
            image_max_size=int(os.getenv('IMAGE_MAX_SIZE', str(10 * 1024 * 1024))),
            streaming_chunk_size=int(os.getenv('STREAMING_CHUNK_SIZE', '8192')),
            fallback_timeout=int(os.getenv('FALLBACK_TIMEOUT', '30')),
            circuit_breaker_threshold=int(os.getenv('CIRCUIT_BREAKER_THRESHOLD', '3')),
            circuit_breaker_timeout=int(os.getenv('CIRCUIT_BREAKER_TIMEOUT', '300')),
            max_concurrent_requests=int(os.getenv('MAX_CONCURRENT_REQUESTS', '10')),
            request_timeout=int(os.getenv('REQUEST_TIMEOUT', '60'))
        )

@dataclass
class MemoryConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é"""
    gemini_api_key: str = ""
    max_short_term_memory_size: int = 10240  # 10KB
    max_long_term_memory_size: int = 10240   # 10KB
    memory_timeout: float = 2.0
    analysis_timeout: float = 5.0
    memory_analysis_model: str = "gemini-2.5-flash-lite"
    memory_analysis_temperature: float = 0.3
    
    @classmethod
    def from_env(cls) -> 'MemoryConfig':
        return cls(
            gemini_api_key=os.getenv('GEMINI_API_KEY', ''),
            max_short_term_memory_size=int(os.getenv('MAX_SHORT_TERM_MEMORY_SIZE', '10240')),
            max_long_term_memory_size=int(os.getenv('MAX_LONG_TERM_MEMORY_SIZE', '10240')),
            memory_timeout=float(os.getenv('MEMORY_TIMEOUT', '2.0')),
            analysis_timeout=float(os.getenv('ANALYSIS_TIMEOUT', '5.0')),
            memory_analysis_model=os.getenv('MEMORY_ANALYSIS_MODEL', 'gemini-2.5-flash-lite'),
            memory_analysis_temperature=float(os.getenv('MEMORY_ANALYSIS_TEMPERATURE', '0.3'))
        )

@dataclass
class SessionConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–µ—Å—Å–∏—è–º–∏"""
    max_sessions: int = 100
    session_timeout: int = 3600  # 1 —á–∞—Å
    hardware_id_length: int = 32
    
    @classmethod
    def from_env(cls) -> 'SessionConfig':
        return cls(
            max_sessions=int(os.getenv('MAX_SESSIONS', '100')),
            session_timeout=int(os.getenv('SESSION_TIMEOUT', '3600')),
            hardware_id_length=int(os.getenv('HARDWARE_ID_LENGTH', '32'))
        )

@dataclass
class InterruptConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è–º–∏"""
    global_interrupt_timeout: int = 300  # 5 –º–∏–Ω—É—Ç
    session_interrupt_timeout: int = 60  # 1 –º–∏–Ω—É—Ç–∞
    max_active_sessions: int = 50
    
    @classmethod
    def from_env(cls) -> 'InterruptConfig':
        return cls(
            global_interrupt_timeout=int(os.getenv('GLOBAL_INTERRUPT_TIMEOUT', '300')),
            session_interrupt_timeout=int(os.getenv('SESSION_INTERRUPT_TIMEOUT', '60')),
            max_active_sessions=int(os.getenv('MAX_ACTIVE_SESSIONS', '50'))
        )

@dataclass
class LoggingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    level: str = "INFO"
    log_requests: bool = True
    log_responses: bool = False
    log_file: str = "server.log"
    max_file_size: int = 10485760  # 10MB
    backup_count: int = 5
    
    @classmethod
    def from_env(cls) -> 'LoggingConfig':
        return cls(
            level=os.getenv('LOG_LEVEL', 'INFO'),
            log_requests=os.getenv('LOG_REQUESTS', 'true').lower() == 'true',
            log_responses=os.getenv('LOG_RESPONSES', 'false').lower() == 'true',
            log_file=os.getenv('LOG_FILE', 'server.log'),
            max_file_size=int(os.getenv('LOG_MAX_FILE_SIZE', '10485760')),
            backup_count=int(os.getenv('LOG_BACKUP_COUNT', '5'))
        )

@dataclass
class UnifiedServerConfig:
    """–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤—Å–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞"""
    database: DatabaseConfig = field(default_factory=DatabaseConfig.from_env)
    grpc: GrpcConfig = field(default_factory=GrpcConfig.from_env)
    audio: AudioConfig = field(default_factory=AudioConfig.from_env)
    text_processing: TextProcessingConfig = field(default_factory=TextProcessingConfig.from_env)
    memory: MemoryConfig = field(default_factory=MemoryConfig.from_env)
    session: SessionConfig = field(default_factory=SessionConfig.from_env)
    interrupt: InterruptConfig = field(default_factory=InterruptConfig.from_env)
    logging: LoggingConfig = field(default_factory=LoggingConfig.from_env)
    
    def __post_init__(self):
        """–ü–æ—Å—Ç-–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        self._validate_config()
    
    def _validate_config(self) -> None:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        errors = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if not self.text_processing.gemini_api_key:
            errors.append("GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        if not self.audio.azure_speech_key:
            errors.append("AZURE_SPEECH_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            
        if not self.audio.azure_speech_region:
            errors.append("AZURE_SPEECH_REGION –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏–π
        if not (0 <= self.text_processing.gemini_live_temperature <= 2):
            errors.append("gemini_live_temperature –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–∂–¥—É 0 –∏ 2")
            
        if not (0.5 <= self.audio.azure_speech_rate <= 2.0):
            errors.append("azure_speech_rate –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–∂–¥—É 0.5 –∏ 2.0")
            
        if self.audio.sample_rate not in [8000, 16000, 22050, 44100, 48000]:
            errors.append("sample_rate –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–¥–Ω–∏–º –∏–∑: 8000, 16000, 22050, 44100, 48000")
        
        # –í—ã–≤–æ–¥–∏–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        for error in errors:
            logger.warning(f"‚ö†Ô∏è {error}")
        
        if errors:
            logger.warning("‚ö†Ô∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–º–µ–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è, –Ω–æ —Å–∏—Å—Ç–µ–º–∞ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å")
    
    def get_module_config(self, module_name: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –º–æ–¥—É–ª—è
        
        Args:
            module_name: –ò–º—è –º–æ–¥—É–ª—è
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –º–æ–¥—É–ª—è
        """
        config_mapping = {
            'database': self.database.__dict__,
            'grpc': self.grpc.__dict__,
            'audio': self.audio.__dict__,
            'text_processing': self.text_processing.__dict__,
            'memory': self.memory.__dict__,
            'session': self.session.__dict__,
            'interrupt': self.interrupt.__dict__,
            'logging': self.logging.__dict__
        }
        
        return config_mapping.get(module_name, {})
    
    def get_provider_config(self, provider_name: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        
        Args:
            provider_name: –ò–º—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        """
        provider_configs = {
            'gemini_live': {
                'api_key': self.text_processing.gemini_api_key,
                'model': self.text_processing.gemini_live_model,
                'temperature': self.text_processing.gemini_live_temperature,
                'max_tokens': self.text_processing.gemini_live_max_tokens,
                'timeout': self.text_processing.request_timeout
            },
            'azure_tts': {
                'speech_key': self.audio.azure_speech_key,
                'speech_region': self.audio.azure_speech_region,
                'voice_name': self.audio.azure_voice_name,
                'voice_style': self.audio.azure_voice_style,
                'speech_rate': self.audio.azure_speech_rate,
                'speech_pitch': self.audio.azure_speech_pitch,
                'speech_volume': self.audio.azure_speech_volume,
                'audio_format': self.audio.azure_audio_format,
                'sample_rate': self.audio.sample_rate,
                'channels': self.audio.channels,
                'bits_per_sample': self.audio.bits_per_sample,
                'timeout': self.text_processing.request_timeout
            },
            'postgresql': {
                'host': self.database.host,
                'port': self.database.port,
                'database': self.database.name,
                'user': self.database.user,
                'password': self.database.password
            }
        }
        
        return provider_configs.get(provider_name, {})
    
    def get_fallback_config(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ fallback –º–µ–Ω–µ–¥–∂–µ—Ä–∞
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π fallback
        """
        return {
            'timeout': self.text_processing.fallback_timeout,
            'circuit_breaker_threshold': self.text_processing.circuit_breaker_threshold,
            'circuit_breaker_timeout': self.text_processing.circuit_breaker_timeout,
            'max_concurrent_requests': self.text_processing.max_concurrent_requests
        }
    
    def get_streaming_config(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ streaming
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π streaming
        """
        return {
            'chunk_size': self.audio.streaming_chunk_size,
            'enabled': self.audio.streaming_enabled,
            'sample_rate': self.audio.sample_rate,
            'channels': self.audio.channels,
            'bits_per_sample': self.audio.bits_per_sample
        }
    
    def save_to_yaml(self, file_path: Union[str, Path]) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤ YAML —Ñ–∞–π–ª
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        """
        config_dict = {
            'database': self.database.__dict__,
            'grpc': self.grpc.__dict__,
            'audio': self.audio.__dict__,
            'text_processing': self.text_processing.__dict__,
            'memory': self.memory.__dict__,
            'session': self.session.__dict__,
            'interrupt': self.interrupt.__dict__,
            'logging': self.logging.__dict__
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            yaml.dump(config_dict, f, default_flow_style=False, allow_unicode=True)
        
        logger.info(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {file_path}")
    
    @classmethod
    def load_from_yaml(cls, file_path: Union[str, Path]) -> 'UnifiedServerConfig':
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ YAML —Ñ–∞–π–ª–∞
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            –≠–∫–∑–µ–º–ø–ª—è—Ä UnifiedServerConfig
        """
        with open(file_path, 'r', encoding='utf-8') as f:
            config_dict = yaml.safe_load(f)
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –∏–∑ —Å–ª–æ–≤–∞—Ä—è
        database = DatabaseConfig(**config_dict.get('database', {}))
        grpc = GrpcConfig(**config_dict.get('grpc', {}))
        audio = AudioConfig(**config_dict.get('audio', {}))
        text_processing = TextProcessingConfig(**config_dict.get('text_processing', {}))
        memory = MemoryConfig(**config_dict.get('memory', {}))
        session = SessionConfig(**config_dict.get('session', {}))
        interrupt = InterruptConfig(**config_dict.get('interrupt', {}))
        logging_config = LoggingConfig(**config_dict.get('logging', {}))
        
        return cls(
            database=database,
            grpc=grpc,
            audio=audio,
            text_processing=text_processing,
            memory=memory,
            session=session,
            interrupt=interrupt,
            logging=logging_config
        )
    
    def get_status(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤—Å–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        """
        return {
            'database': {
                'host': self.database.host,
                'port': self.database.port,
                'name': self.database.name,
                'user': self.database.user,
                'password_set': bool(self.database.password)
            },
            'grpc': self.grpc.__dict__,
            'audio': {
                'sample_rate': self.audio.sample_rate,
                'chunk_size': self.audio.chunk_size,
                'format': self.audio.format,
                'azure_speech_key_set': bool(self.audio.azure_speech_key),
                'azure_speech_region_set': bool(self.audio.azure_speech_region),
                'azure_voice_name': self.audio.azure_voice_name,
                'streaming_enabled': self.audio.streaming_enabled
            },
            'text_processing': {
                'gemini_api_key_set': bool(self.text_processing.gemini_api_key),
                'gemini_live_model': self.text_processing.gemini_live_model,
                'gemini_live_temperature': self.text_processing.gemini_live_temperature,
                'max_concurrent_requests': self.text_processing.max_concurrent_requests
            },
            'memory': {
                'gemini_api_key_set': bool(self.memory.gemini_api_key),
                'max_short_term_memory_size': self.memory.max_short_term_memory_size,
                'max_long_term_memory_size': self.memory.max_long_term_memory_size,
                'memory_timeout': self.memory.memory_timeout
            },
            'session': self.session.__dict__,
            'interrupt': self.interrupt.__dict__,
            'logging': self.logging.__dict__
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
_config_instance: Optional[UnifiedServerConfig] = None

def get_config() -> UnifiedServerConfig:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    
    Returns:
        –≠–∫–∑–µ–º–ø–ª—è—Ä UnifiedServerConfig
    """
    global _config_instance
    if _config_instance is None:
        _config_instance = UnifiedServerConfig()
        logger.info("‚úÖ –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    return _config_instance

def reload_config() -> UnifiedServerConfig:
    """
    –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    
    Returns:
        –ù–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä UnifiedServerConfig
    """
    global _config_instance
    _config_instance = UnifiedServerConfig()
    logger.info("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    return _config_instance

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = get_config()
    print("üìä –°—Ç–∞—Ç—É—Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")
    status = config.get_status()
    
    for section, values in status.items():
        print(f"\nüîß {section.upper()}:")
        for key, value in values.items():
            print(f"  {key}: {value}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config.save_to_yaml("server/config/unified_config_example.yaml")
    print("\n‚úÖ –ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ server/config/unified_config_example.yaml")
